# OpenAI API Configuration Example (Not yet tested)
nya_proxy:
  host: 0.0.0.0
  port: 8080
  api_key: 
  logging:
    enabled: true
    level: info
    log_file: nya_proxy.log
  proxy:
    enabled: false
    address: socks5://username:password@proxy.example.com:1080
  dashboard:
    enabled: true
  queue:
    enabled: true
    max_size: 200
    expiry_seconds: 300
    
default_settings:
  key_variable: keys
  load_balancing_strategy: round_robin
  rate_limit:
    endpoint_rate_limit: 10/s
    key_rate_limit: 10/m
  retry:
    enabled: true
    attempts: 3
    retry_after_seconds: 10
  timeouts:
    request_timeout_seconds: 30
  error_handling:
    report_api_errors: true
    retry_status_codes:
    - 429
    - 500
    - 502
    - 503
    - 504

apis:
  openai:
    name: "OpenAI API"
    endpoint: "https://api.openai.com"
    key_variable: "keys"
    headers:
      Authorization: "Bearer ${{keys}}"
      Content-Type: "application/json"
      OpenAI-Organization: "${{organization}}"  # Optional organization ID
    variables:
      keys:
        - "sk-your-openai-key-1"
        - "sk-your-openai-key-2"
        - "sk-your-openai-key-3"
      organization:
        - "org-your-organization-id"  # Remove if not using organization
    load_balancing_strategy: "least_requests"
    rate_limit:
      endpoint_rate_limit: "3500/m"  # Conservative estimate
      key_rate_limit: "1200/m"       # Depends on your OpenAI tier
    retry:
      enabled: true
      attempts: 5
      retry_after_seconds: 2
    timeouts:
      request_timeout_seconds: 120    # Increased timeout for chat completions
    error_handling:
      retry_status_codes: [429, 500, 502, 503, 504]
      report_api_errors: true